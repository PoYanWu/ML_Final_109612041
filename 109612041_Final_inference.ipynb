{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import joblib \n",
    "import torch\n",
    "from torch import nn\n",
    "import sklearn\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "\n",
    "train_df = pd.read_csv(\"tabular-playground-series-aug-2022//train.csv\")\n",
    "test_df = pd.read_csv(\"tabular-playground-series-aug-2022//test.csv\")\n",
    "\n",
    "ID = test_df['id']\n",
    "\n",
    "# concat train and test data for imputation\n",
    "all_df = pd.concat([train_df[test_df.columns], test_df], ignore_index=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['measurement_3', 'measurement_4', 'measurement_5', 'measurement_6', 'measurement_7', 'measurement_8', 'measurement_9', 'measurement_10', 'measurement_11', 'measurement_12', 'measurement_13', 'measurement_14', 'measurement_15', 'measurement_16'] ['id', 'attribute_2', 'attribute_3', 'measurement_0', 'measurement_1', 'measurement_2']\n"
     ]
    }
   ],
   "source": [
    "float_columns = test_df.dtypes[test_df.dtypes == 'float64'].index.tolist()\n",
    "float_columns.remove('measurement_17')\n",
    "float_columns.remove('loading')\n",
    "int_columns = test_df.dtypes[test_df.dtypes == 'int64'].index.tolist()\n",
    "print(float_columns, int_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop id and not numerical columns\n",
    "#all_df.drop(['id'], axis=1, inplace=True)\n",
    "all_df = all_df.drop(['product_code', 'attribute_0', 'attribute_1'], axis=1)\n",
    "columns = all_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df['m_3_missing'] = all_df.measurement_3.isna()\n",
    "all_df['m_5_missing'] = all_df.measurement_5.isna()\n",
    "\n",
    "# imputation\n",
    "\n",
    "imp = KNNImputer(n_neighbors=10)\n",
    "std_scaler = StandardScaler()\n",
    "for i in all_df.columns:\n",
    "  \n",
    "  all_df[[i]] = imp.fit_transform(all_df[[i]])\n",
    "\n",
    "\n",
    "# use imputed data to calculate \"attribute_2\" * \"attribute_3\", stdev, avg from \"measurement_0\" to \"measurement_16\" of each row as extra features\n",
    "a = all_df['attribute_2']\n",
    "b = all_df['attribute_3']\n",
    "area = a*b\n",
    "all_df['area'] = area\n",
    "\n",
    "stdev = np.std(all_df[float_columns], axis=1)\n",
    "all_df['stdev'] = stdev\n",
    "\n",
    "avg = np.average(all_df[float_columns], axis=1)\n",
    "all_df['avg'] = avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = all_df.drop(int_columns, axis=1)\n",
    "all_df = all_df.drop(float_columns, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_to_scale = ['loading', 'avg', 'stdev', 'area', 'measurement_17']\n",
    "\n",
    "# standardscaling\n",
    "all_df[col_to_scale] = std_scaler.fit_transform(all_df[col_to_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = all_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split x, y\n",
    "\n",
    "x_train = full_data.iloc[:train_df.shape[0], :]\n",
    "y_train = train_df['failure'].astype('float')\n",
    "x_test = full_data.iloc[train_df.shape[0]:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = (torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu'))\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class test_ds(Dataset):\n",
    "  def __init__(self, x_test):\n",
    "    \n",
    "    self.X_test = torch.from_numpy(x_test.values.astype(np.float32))\n",
    "  \n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.X_test)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    return self.X_test[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_ds(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dl = DataLoader(test_data, batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_num = x_train.shape[1]\n",
    "\n",
    "torch.manual_seed(32)\n",
    "\n",
    "class LinearModel(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.layer1 = nn.Linear(in_features=col_num, out_features=8)\n",
    "    self.layer2 = nn.Linear(in_features=16, out_features=8)\n",
    "    self.layer3 = nn.Linear(in_features=8, out_features=8)\n",
    "    self.layer4 = nn.Linear(in_features=8, out_features=1)\n",
    "\n",
    "    self.relu = nn.ReLU()\n",
    "    self.batch_norm1 = nn.BatchNorm1d(16)\n",
    "    self.batch_norm2 = nn.BatchNorm1d(31)\n",
    "    self.dropout = nn.Dropout(p=0.2)\n",
    "\n",
    "\n",
    "  def forward(self, x: torch.tensor):\n",
    "      #x = self.dropout(x)\n",
    "      x = self.relu(self.layer1(x))\n",
    "      x = self.dropout(x)\n",
    "      x = self.layer3(x)\n",
    "      x = self.layer4(x)\n",
    "\n",
    "      return x\n",
    "\n",
    "model = LinearModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load('my_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = []\n",
    "\n",
    "model.eval()\n",
    "for x_test in test_dl:\n",
    "  x_test = x_test.to(device)\n",
    "  with torch.inference_mode():\n",
    "    test_pred = model(x_test)\n",
    "    test_pred_value = test_pred.cpu().numpy()\n",
    "    test_loss.append(test_pred_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = []\n",
    "for sublist in test_loss:\n",
    "    for item in sublist:\n",
    "        pred.append(item[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_list = []\n",
    "for i in range(len(ID)):\n",
    "    write_list.append((ID[i], pred[i]))\n",
    "csv_writer = csv.writer(open(\"109612041.csv\", mode = 'w', newline=''))\n",
    "csv_writer.writerow(['id', 'failure'])\n",
    "for id, f in write_list:\n",
    "    csv_writer.writerow([id, f])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "21bfaabeb5f90dcb35f03e41cd0a17fbadd35308efdf98a46f30b833cf085000"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
